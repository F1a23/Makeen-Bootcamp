{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f84b7cd-a007-4990-90b8-07035e3b8267",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER PC\\anaconda3\\Lib\\site-packages\\keras\\src\\export\\tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4357f0c-7aea-47b3-b673-dd691c44076d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 1) Load CIFAR-10\n",
    "# =========================\n",
    "(x_train, _), (_, _) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Normalize to [-1, 1] (because generator uses tanh)\n",
    "x_train = x_train.astype(\"float32\")\n",
    "x_train = (x_train - 127.5) / 127.5  # [-1, 1]\n",
    "\n",
    "BUFFER_SIZE = x_train.shape[0]\n",
    "BATCH_SIZE = 256\n",
    "LATENT_DIM = 128\n",
    "EPOCHS = 50\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(x_train)\n",
    "train_ds = train_ds.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afb30457-27f4-4cf7-99a6-388248f15cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 2) Generator (32x32x3)\n",
    "# =========================\n",
    "def build_generator(latent_dim=128):\n",
    "    model = keras.Sequential(name=\"Generator\")\n",
    "    model.add(layers.Input(shape=(latent_dim,)))\n",
    "\n",
    "    # Start from 4x4\n",
    "    model.add(layers.Dense(4 * 4 * 512, use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU(0.2))\n",
    "    model.add(layers.Reshape((4, 4, 512)))  # (4,4,512)\n",
    "\n",
    "    # 8x8\n",
    "    model.add(layers.Conv2DTranspose(256, 4, strides=2, padding=\"same\", use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU(0.2))\n",
    "\n",
    "    # 16x16\n",
    "    model.add(layers.Conv2DTranspose(128, 4, strides=2, padding=\"same\", use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU(0.2))\n",
    "\n",
    "    # 32x32\n",
    "    model.add(layers.Conv2DTranspose(64, 4, strides=2, padding=\"same\", use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU(0.2))\n",
    "\n",
    "    # Output 32x32x3 (RGB) in [-1, 1]\n",
    "    model.add(layers.Conv2DTranspose(3, 3, strides=1, padding=\"same\", activation=\"tanh\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a25cdae-2838-4d48-abee-fd6fd1c039b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 3) Discriminator (32x32x3)\n",
    "# =========================\n",
    "def build_discriminator():\n",
    "    model = keras.Sequential(name=\"Discriminator\")\n",
    "    model.add(layers.Input(shape=(32, 32, 3)))\n",
    "\n",
    "    model.add(layers.Conv2D(64, 4, strides=2, padding=\"same\"))\n",
    "    model.add(layers.LeakyReLU(0.2))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(128, 4, strides=2, padding=\"same\"))\n",
    "    model.add(layers.LeakyReLU(0.2))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(256, 4, strides=2, padding=\"same\"))\n",
    "    model.add(layers.LeakyReLU(0.2))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))  # logits\n",
    "    return model\n",
    "\n",
    "generator = build_generator(LATENT_DIM)\n",
    "discriminator = build_discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8aaa8952-99d7-4c19-bed4-dfbbbe48c2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 4) Loss + Optimizers\n",
    "# =========================\n",
    "bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def d_loss_fn(real_logits, fake_logits):\n",
    "    real_loss = bce(tf.ones_like(real_logits), real_logits)\n",
    "    fake_loss = bce(tf.zeros_like(fake_logits), fake_logits)\n",
    "    return real_loss + fake_loss\n",
    "\n",
    "def g_loss_fn(fake_logits):\n",
    "    return bce(tf.ones_like(fake_logits), fake_logits)\n",
    "\n",
    "gen_opt = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "disc_opt = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b2366b6-8730-4ed5-8376-144d945215bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 5) Save samples\n",
    "# =========================\n",
    "os.makedirs(\"cifar_gan_samples\", exist_ok=True)\n",
    "SEED = tf.random.normal([16, LATENT_DIM])\n",
    "\n",
    "def save_generated(epoch):\n",
    "    imgs = generator(SEED, training=False)      # [-1,1]\n",
    "    imgs = (imgs + 1.0) / 2.0                   # [0,1]\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    for i in range(16):\n",
    "        plt.subplot(4, 4, i + 1)\n",
    "        plt.imshow(imgs[i])\n",
    "        plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"cifar_gan_samples/epoch_{epoch:03d}.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa65c8ae-71e1-4e38-a591-b4445610189d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 6) Train Step\n",
    "# =========================\n",
    "@tf.function\n",
    "def train_step(real_images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, LATENT_DIM])\n",
    "\n",
    "    with tf.GradientTape() as gtape, tf.GradientTape() as dtape:\n",
    "        fake_images = generator(noise, training=True)\n",
    "\n",
    "        real_logits = discriminator(real_images, training=True)\n",
    "        fake_logits = discriminator(fake_images, training=True)\n",
    "\n",
    "        d_loss = d_loss_fn(real_logits, fake_logits)\n",
    "        g_loss = g_loss_fn(fake_logits)\n",
    "\n",
    "    g_grads = gtape.gradient(g_loss, generator.trainable_variables)\n",
    "    d_grads = dtape.gradient(d_loss, discriminator.trainable_variables)\n",
    "\n",
    "    gen_opt.apply_gradients(zip(g_grads, generator.trainable_variables))\n",
    "    disc_opt.apply_gradients(zip(d_grads, discriminator.trainable_variables))\n",
    "\n",
    "    return g_loss, d_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fdf9ad-fb5f-496b-b939-a844dc70463d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 7) Training Loop\n",
    "# =========================\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    g_losses, d_losses = [], []\n",
    "    for real_batch in train_ds:\n",
    "        g_loss, d_loss = train_step(real_batch)\n",
    "        g_losses.append(g_loss)\n",
    "        d_losses.append(d_loss)\n",
    "\n",
    "    save_generated(epoch)\n",
    "    print(f\"Epoch {epoch}/{EPOCHS} | G Loss: {tf.reduce_mean(g_losses):.4f} | D Loss: {tf.reduce_mean(d_losses):.4f}\")\n",
    "\n",
    "print(\" Done! Check folder: cifar_gan_samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f124f522-fa42-40f1-97a9-01e0a4613089",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
