{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOJpmD2k2ScY/gvn18C2k63"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sCYLED9inM0h","executionInfo":{"status":"ok","timestamp":1766047240707,"user_tz":-240,"elapsed":48628,"user":{"displayName":"CA Events","userId":"12956334802148352282"}},"outputId":"43b9ceb6-0c72-4783-eaff-ae7094cf89c1"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\n","--- Learned Hidden Layer Weights ---\n","Weights (Input → Hidden):\n","[[ 1.6168997  -0.30793193]\n"," [-0.200043   -0.83184624]\n"," [ 1.4369265   0.5013206 ]]\n","Biases (Hidden Layer):\n","[ 0.20024802 -0.21062355]\n","\n","--- Learned Output Layer Weights ---\n","Weights (Hidden → Output):\n","[[ 0.53833777]\n"," [-1.2381511 ]]\n","Bias (Output Layer):\n","[-0.09057542]\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n","\n","Spam Probability for [1, 0, 1]: 0.8404011\n","Final Classification: Spam (1)\n"]}],"source":["import tensorflow as tf\n","import numpy as np\n","\n","# =====================================================\n","# 1. TRAINING DATA\n","# =====================================================\n","# Each input represents words in an email:\n","# [free, win, offer]\n","# 1 = word present, 0 = word absent\n","X = np.array([\n","    [1, 0, 1],   # spam email\n","    [0, 1, 1],   # spam email\n","    [0, 0, 0],   # not spam\n","    [1, 1, 1],   # spam email\n","    [0, 1, 0]    # not spam\n","], dtype=np.float32)\n","\n","# Labels:\n","# 1 = spam, 0 = not spam\n","y = np.array([1, 1, 0, 1, 0], dtype=np.float32)\n","\n","# =====================================================\n","# 2. BUILD THE NEURAL NETWORK\n","# =====================================================\n","# Architecture:\n","# - Input layer: 3 features\n","# - Hidden layer: 2 neurons with ReLU\n","# - Output layer: 1 neuron with Sigmoid\n","model = tf.keras.Sequential([\n","    tf.keras.layers.Dense(\n","        units=2,               # Two hidden neurons (H1, H2)\n","        activation='relu',     # ReLU activation\n","        input_shape=(3,),      # Three input features\n","        name=\"Hidden_Layer\"\n","    ),\n","    tf.keras.layers.Dense(\n","        units=1,               # One output neuron\n","        activation='sigmoid',  # Sigmoid gives probability\n","        name=\"Output_Layer\"\n","    )\n","])\n","\n","# =====================================================\n","# 3. COMPILE THE MODEL\n","# =====================================================\n","# - Adam optimizer updates weights automatically\n","# - Binary crossentropy is used for binary classification\n","model.compile(\n","    optimizer='adam',\n","    loss='binary_crossentropy',\n","    metrics=['accuracy']\n",")\n","\n","# =====================================================\n","# 4. TRAIN THE MODEL\n","# =====================================================\n","# During training:\n","# - Weights are initialized randomly\n","# - Forward pass computes predictions\n","# - Loss is calculated\n","# - Backpropagation updates weights\n","model.fit(\n","    X,\n","    y,\n","    epochs=500,   # Train multiple times to learn better weights\n","    verbose=0     # Hide training output\n",")\n","\n","# =====================================================\n","# 5. PRINT LEARNED WEIGHTS\n","# =====================================================\n","print(\"\\n--- Learned Hidden Layer Weights ---\")\n","\n","# Get weights and biases of hidden layer\n","hidden_weights, hidden_bias = model.layers[0].get_weights()\n","\n","print(\"Weights (Input → Hidden):\")\n","print(hidden_weights)   # Shape: (3 inputs, 2 neurons)\n","\n","print(\"Biases (Hidden Layer):\")\n","print(hidden_bias)\n","\n","print(\"\\n--- Learned Output Layer Weights ---\")\n","\n","# Get weights and bias of output layer\n","output_weights, output_bias = model.layers[1].get_weights()\n","\n","print(\"Weights (Hidden → Output):\")\n","print(output_weights)   # Shape: (2 hidden neurons, 1 output)\n","\n","print(\"Bias (Output Layer):\")\n","print(output_bias)\n","\n","# =====================================================\n","# 6. TEST PREDICTION\n","# =====================================================\n","# Test with an example email: free=1, win=0, offer=1\n","test_input = np.array([[1, 0, 1]], dtype=np.float32)\n","\n","# Forward pass only (no training)\n","prediction = model.predict(test_input)\n","\n","print(\"\\nSpam Probability for [1, 0, 1]:\", prediction[0][0])\n","\n","# Final decision using threshold 0.5\n","if prediction[0][0] > 0.5:\n","    print(\"Final Classification: Spam (1)\")\n","else:\n","    print(\"Final Classification: Not Spam (0)\")"]}]}